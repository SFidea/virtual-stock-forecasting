{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, 导入包及其他相关准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_path = './data/stock_group_1.pickle'\n",
    "def load_data(f_path):\n",
    "    data = None\n",
    "    if os.path.exists(f_path):\n",
    "        try:\n",
    "            f = open(f_path, 'rb')\n",
    "            data = pickle.load(f)\n",
    "            f.close()\n",
    "        except Exception as e:\n",
    "            print('Unable to read data: ', e)\n",
    "            raise\n",
    "    else:\n",
    "        print('Data file not exists.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9442, 88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_dataset'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9442, 88)\n",
      "(9442, 88, 1)\n"
     ]
    }
   ],
   "source": [
    "data_train = data['train_dataset']\n",
    "print(data_train.shape)\n",
    "print(data_train.reshape(-1,88,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(data, weights, labels, batch_size):\n",
    "    data_len = len(data)\n",
    "    for i in range(0, data_len, batch_size):\n",
    "        end = i + batch_size\n",
    "        if end > data_len:\n",
    "            end = -1\n",
    "        x = data[i: end].reshape(-1,data.shape[1],1)\n",
    "        #print(x.shape)\n",
    "        y = labels[i : end]\n",
    "        w = weights[i: end]\n",
    "        yield x, y, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2, 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(num_features):\n",
    "    '''\n",
    "    构建输入\n",
    "    '''\n",
    "    inputs = tf.placeholder(tf.float32, [None, num_features, 1], name='inputs')\n",
    "    targets = tf.placeholder(tf.float32, [None, 1], name='targets')\n",
    "    weights = tf.placeholder(tf.float32, [None, 1], name='weights')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    return inputs, targets, weights, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resNet(inputs, num_features, layers, init_channel,filter_size, keep_prob, res_deep = 3, use_max_pool = False):\n",
    "    '''\n",
    "    残差网络\n",
    "    '''\n",
    "    layer_input = inputs\n",
    "    layer_res = inputs\n",
    "    channels = init_channel\n",
    "    out_size = num_features\n",
    "    \n",
    "    padding = 'valid'\n",
    "    if use_max_pool:\n",
    "        padding = 'same'\n",
    "    for i in range(1,layers + 1):\n",
    "        C1 = tf.layers.conv1d(layer_input, \n",
    "                              channels,\n",
    "                              filter_size,\n",
    "                              padding=padding,\n",
    "                              activation=tf.nn.elu,\n",
    "                              kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer_input = C1\n",
    "        if not use_max_pool:\n",
    "            out_size = out_size - filter_size + 1\n",
    "        if i % res_deep == 0:\n",
    "            channels = 2 * channels\n",
    "            if not use_max_pool:\n",
    "                C2 = tf.layers.conv1d(layer_res, \n",
    "                                      channels,\n",
    "                                      (num_features - out_size) + 1,\n",
    "                                      padding=padding,\n",
    "                                      activation=tf.nn.elu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                C3 = tf.layers.conv1d(layer_input, \n",
    "                                      channels,\n",
    "                                      1,\n",
    "                                      padding=padding,\n",
    "                                      activation=tf.nn.elu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                layer_input = C2 + C3\n",
    "            else:\n",
    "                layer_input = tf.layers.max_pooling1d((layer_res + C1), pool_size=4, strides=2, padding='same')\n",
    "                layer_res = tf.layers.conv1d(layer_input, \n",
    "                                             channels,\n",
    "                                             1,\n",
    "                                             padding=padding,\n",
    "                                             activation=tf.nn.elu,\n",
    "                                             kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    return layer_input, layer_input.get_shape().as_list()[1], layer_input.get_shape().as_list()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(inputs, num_features, keep_prob, layers = 4, init_channel = 16, filter_size = 5):\n",
    "    '''\n",
    "    建立模型\n",
    "    ''' \n",
    "    c1 = tf.layers.conv1d(inputs, init_channel, 1, padding='valid', \n",
    "                      activation=None, \n",
    "                      kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    layers_out, out_size, channels = resNet(c1, \n",
    "                                              num_features, \n",
    "                                              layers, \n",
    "                                              init_channel, \n",
    "                                              filter_size, \n",
    "                                              keep_prob,\n",
    "                                              4,\n",
    "                                              False)\n",
    "    print('out size: ',out_size)\n",
    "    print('channels: ',channels)\n",
    "    layers_out_flat = tf.reshape(layers_out, (-1, out_size * channels))\n",
    "    \n",
    "    h = tf.layers.dense(layers_out_flat,256,activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    logits = tf.layers.dense(h, 1, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#超参数\n",
    "num_features = 88\n",
    "batch_size = 1024\n",
    "learning_rate = 0.0003\n",
    "epochs = 10\n",
    "kp = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3, 调用建模函数，建图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out size:  72\n",
      "channels:  32\n"
     ]
    }
   ],
   "source": [
    "inputs, targets, weights, keep_prob = build_inputs(num_features)\n",
    "\n",
    "logits = build_model(inputs, num_features, keep_prob)\n",
    "\n",
    "out = tf.sigmoid(logits)\n",
    "\n",
    "#回归weights\n",
    "#targets_ = tf.sigmoid(weights)\n",
    "\n",
    "entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=targets)\n",
    "#entropy = tf.pow((logits - weights),2)\n",
    "\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "pre_out = tf.reduce_mean(tf.round(out))\n",
    "\n",
    "correct_pred = tf.equal(tf.cast(tf.round(out), tf.int32), tf.cast(targets, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10.  Train Step: 1.  pre_out: 0.5626. Train acc: 0.5146.  Valid acc: 0.4743.  0.3754 sec/batch\n",
      "Epoch: 1/10.  Train Step: 2.  pre_out: 0.2925. Train acc: 0.5049.  Valid acc: 0.4545.  0.3495 sec/batch\n",
      "Epoch: 1/10.  Train Step: 3.  pre_out: 0.2762. Train acc: 0.5283.  Valid acc: 0.5086.  0.3539 sec/batch\n",
      "Epoch: 1/10.  Train Step: 4.  pre_out: 0.4074. Train acc: 0.5508.  Valid acc: 0.5283.  0.3501 sec/batch\n",
      "Epoch: 1/10.  Train Step: 5.  pre_out: 0.4537. Train acc: 0.5557.  Valid acc: 0.5283.  0.3564 sec/batch\n",
      "Epoch: 1/10.  Train Step: 6.  pre_out: 0.4708. Train acc: 0.5674.  Valid acc: 0.4940.  0.3561 sec/batch\n",
      "Epoch: 1/10.  Train Step: 7.  pre_out: 0.5695. Train acc: 0.5518.  Valid acc: 0.4897.  0.3438 sec/batch\n",
      "Epoch: 1/10.  Train Step: 8.  pre_out: 0.6304. Train acc: 0.5840.  Valid acc: 0.4889.  0.3508 sec/batch\n",
      "Epoch: 1/10.  Train Step: 9.  pre_out: 0.6329. Train acc: 0.5801.  Valid acc: 0.4743.  0.3523 sec/batch\n",
      "Epoch: 1/10.  Train Step: 10.  pre_out: 0.6055. Train acc: 0.5600.  Valid acc: 0.4914.  0.1383 sec/batch\n",
      "Epoch: 2/10.  Train Step: 11.  pre_out: 0.5763. Train acc: 0.6016.  Valid acc: 0.5069.  0.3660 sec/batch\n",
      "Epoch: 2/10.  Train Step: 12.  pre_out: 0.5532. Train acc: 0.6035.  Valid acc: 0.4957.  0.4084 sec/batch\n",
      "Epoch: 2/10.  Train Step: 13.  pre_out: 0.5377. Train acc: 0.6182.  Valid acc: 0.4957.  0.3790 sec/batch\n",
      "Epoch: 2/10.  Train Step: 14.  pre_out: 0.5480. Train acc: 0.6084.  Valid acc: 0.4974.  0.3438 sec/batch\n",
      "Epoch: 2/10.  Train Step: 15.  pre_out: 0.5780. Train acc: 0.5732.  Valid acc: 0.4846.  0.3535 sec/batch\n",
      "Epoch: 2/10.  Train Step: 16.  pre_out: 0.5943. Train acc: 0.6143.  Valid acc: 0.4786.  0.3487 sec/batch\n",
      "Epoch: 2/10.  Train Step: 17.  pre_out: 0.6269. Train acc: 0.6289.  Valid acc: 0.4768.  0.3453 sec/batch\n",
      "Epoch: 2/10.  Train Step: 18.  pre_out: 0.6244. Train acc: 0.6162.  Valid acc: 0.4846.  0.3617 sec/batch\n",
      "Epoch: 2/10.  Train Step: 19.  pre_out: 0.6192. Train acc: 0.6182.  Valid acc: 0.4846.  0.3498 sec/batch\n",
      "Epoch: 2/10.  Train Step: 20.  pre_out: 0.5823. Train acc: 0.6533.  Valid acc: 0.4906.  0.1379 sec/batch\n",
      "Epoch: 3/10.  Train Step: 21.  pre_out: 0.5377. Train acc: 0.6230.  Valid acc: 0.4854.  0.3725 sec/batch\n",
      "Epoch: 3/10.  Train Step: 22.  pre_out: 0.5017. Train acc: 0.6133.  Valid acc: 0.4803.  0.3471 sec/batch\n",
      "Epoch: 3/10.  Train Step: 23.  pre_out: 0.4794. Train acc: 0.6152.  Valid acc: 0.4820.  0.3872 sec/batch\n",
      "Epoch: 3/10.  Train Step: 24.  pre_out: 0.4563. Train acc: 0.6387.  Valid acc: 0.4726.  0.4508 sec/batch\n",
      "Epoch: 3/10.  Train Step: 25.  pre_out: 0.4640. Train acc: 0.5918.  Valid acc: 0.4683.  0.4464 sec/batch\n",
      "Epoch: 3/10.  Train Step: 26.  pre_out: 0.4657. Train acc: 0.6299.  Valid acc: 0.4528.  0.4475 sec/batch\n",
      "Epoch: 3/10.  Train Step: 27.  pre_out: 0.4991. Train acc: 0.6387.  Valid acc: 0.4485.  0.4490 sec/batch\n",
      "Epoch: 3/10.  Train Step: 28.  pre_out: 0.5232. Train acc: 0.6465.  Valid acc: 0.4468.  0.4268 sec/batch\n",
      "Epoch: 3/10.  Train Step: 29.  pre_out: 0.5420. Train acc: 0.6514.  Valid acc: 0.4434.  0.4467 sec/batch\n",
      "Epoch: 3/10.  Train Step: 30.  pre_out: 0.5592. Train acc: 0.6756.  Valid acc: 0.4708.  0.1532 sec/batch\n",
      "Epoch: 4/10.  Train Step: 31.  pre_out: 0.5763. Train acc: 0.6357.  Valid acc: 0.4828.  0.3665 sec/batch\n",
      "Epoch: 4/10.  Train Step: 32.  pre_out: 0.5926. Train acc: 0.6221.  Valid acc: 0.4871.  0.3586 sec/batch\n",
      "Epoch: 4/10.  Train Step: 33.  pre_out: 0.6055. Train acc: 0.6230.  Valid acc: 0.4811.  0.3597 sec/batch\n",
      "Epoch: 4/10.  Train Step: 34.  pre_out: 0.6175. Train acc: 0.6406.  Valid acc: 0.4914.  0.3493 sec/batch\n",
      "Epoch: 4/10.  Train Step: 35.  pre_out: 0.6269. Train acc: 0.6289.  Valid acc: 0.4734.  0.3515 sec/batch\n",
      "Epoch: 4/10.  Train Step: 36.  pre_out: 0.5969. Train acc: 0.6475.  Valid acc: 0.4674.  0.3562 sec/batch\n",
      "Epoch: 4/10.  Train Step: 37.  pre_out: 0.5815. Train acc: 0.6504.  Valid acc: 0.4503.  0.3437 sec/batch\n",
      "Epoch: 4/10.  Train Step: 38.  pre_out: 0.5549. Train acc: 0.6475.  Valid acc: 0.4425.  0.3485 sec/batch\n",
      "Epoch: 4/10.  Train Step: 39.  pre_out: 0.5660. Train acc: 0.6582.  Valid acc: 0.4400.  0.4292 sec/batch\n",
      "Epoch: 4/10.  Train Step: 40.  pre_out: 0.5712. Train acc: 0.7422.  Valid acc: 0.4571.  0.1779 sec/batch\n",
      "Epoch: 5/10.  Train Step: 41.  pre_out: 0.5789. Train acc: 0.6621.  Valid acc: 0.4648.  0.3564 sec/batch\n",
      "Epoch: 5/10.  Train Step: 42.  pre_out: 0.5806. Train acc: 0.6357.  Valid acc: 0.4683.  0.3947 sec/batch\n",
      "Epoch: 5/10.  Train Step: 43.  pre_out: 0.6046. Train acc: 0.6416.  Valid acc: 0.4717.  0.4101 sec/batch\n",
      "Epoch: 5/10.  Train Step: 44.  pre_out: 0.6329. Train acc: 0.6631.  Valid acc: 0.4794.  0.4286 sec/batch\n",
      "Epoch: 5/10.  Train Step: 45.  pre_out: 0.6321. Train acc: 0.6426.  Valid acc: 0.4717.  0.3406 sec/batch\n",
      "Epoch: 5/10.  Train Step: 46.  pre_out: 0.5926. Train acc: 0.6504.  Valid acc: 0.4648.  0.4002 sec/batch\n",
      "Epoch: 5/10.  Train Step: 47.  pre_out: 0.5660. Train acc: 0.6504.  Valid acc: 0.4537.  0.3457 sec/batch\n",
      "Epoch: 5/10.  Train Step: 48.  pre_out: 0.5455. Train acc: 0.6592.  Valid acc: 0.4485.  0.3894 sec/batch\n",
      "Epoch: 5/10.  Train Step: 49.  pre_out: 0.5515. Train acc: 0.6592.  Valid acc: 0.4580.  0.4106 sec/batch\n",
      "Epoch: 5/10.  Train Step: 50.  pre_out: 0.5557. Train acc: 0.7644.  Valid acc: 0.4588.  0.1385 sec/batch\n",
      "Epoch: 6/10.  Train Step: 51.  pre_out: 0.5600. Train acc: 0.6660.  Valid acc: 0.4563.  0.3845 sec/batch\n",
      "Epoch: 6/10.  Train Step: 52.  pre_out: 0.5669. Train acc: 0.6455.  Valid acc: 0.4494.  0.4406 sec/batch\n",
      "Epoch: 6/10.  Train Step: 53.  pre_out: 0.5969. Train acc: 0.6582.  Valid acc: 0.4554.  0.3638 sec/batch\n",
      "Epoch: 6/10.  Train Step: 54.  pre_out: 0.6184. Train acc: 0.6777.  Valid acc: 0.4648.  0.3488 sec/batch\n",
      "Epoch: 6/10.  Train Step: 55.  pre_out: 0.6338. Train acc: 0.6562.  Valid acc: 0.4580.  0.3505 sec/batch\n",
      "Epoch: 6/10.  Train Step: 56.  pre_out: 0.6046. Train acc: 0.6670.  Valid acc: 0.4528.  0.3529 sec/batch\n",
      "Epoch: 6/10.  Train Step: 57.  pre_out: 0.5986. Train acc: 0.6611.  Valid acc: 0.4451.  0.3495 sec/batch\n",
      "Epoch: 6/10.  Train Step: 58.  pre_out: 0.5840. Train acc: 0.6738.  Valid acc: 0.4528.  0.3502 sec/batch\n",
      "Epoch: 6/10.  Train Step: 59.  pre_out: 0.5926. Train acc: 0.6572.  Valid acc: 0.4648.  0.3468 sec/batch\n",
      "Epoch: 6/10.  Train Step: 60.  pre_out: 0.5961. Train acc: 0.7778.  Valid acc: 0.4648.  0.1352 sec/batch\n",
      "Epoch: 7/10.  Train Step: 61.  pre_out: 0.5995. Train acc: 0.6719.  Valid acc: 0.4614.  0.3505 sec/batch\n",
      "Epoch: 7/10.  Train Step: 62.  pre_out: 0.5746. Train acc: 0.6611.  Valid acc: 0.4640.  0.3464 sec/batch\n",
      "Epoch: 7/10.  Train Step: 63.  pre_out: 0.5815. Train acc: 0.6680.  Valid acc: 0.4503.  0.3505 sec/batch\n",
      "Epoch: 7/10.  Train Step: 64.  pre_out: 0.5901. Train acc: 0.6826.  Valid acc: 0.4571.  0.3481 sec/batch\n",
      "Epoch: 7/10.  Train Step: 65.  pre_out: 0.5935. Train acc: 0.6592.  Valid acc: 0.4503.  0.3488 sec/batch\n",
      "Epoch: 7/10.  Train Step: 66.  pre_out: 0.5626. Train acc: 0.6758.  Valid acc: 0.4520.  0.3521 sec/batch\n",
      "Epoch: 7/10.  Train Step: 67.  pre_out: 0.5772. Train acc: 0.6738.  Valid acc: 0.4477.  0.3482 sec/batch\n",
      "Epoch: 7/10.  Train Step: 68.  pre_out: 0.5840. Train acc: 0.6797.  Valid acc: 0.4545.  0.3465 sec/batch\n",
      "Epoch: 7/10.  Train Step: 69.  pre_out: 0.6063. Train acc: 0.6670.  Valid acc: 0.4631.  0.3470 sec/batch\n",
      "Epoch: 7/10.  Train Step: 70.  pre_out: 0.6098. Train acc: 0.7867.  Valid acc: 0.4751.  0.1381 sec/batch\n",
      "Epoch: 8/10.  Train Step: 71.  pre_out: 0.6046. Train acc: 0.6807.  Valid acc: 0.4734.  0.3599 sec/batch\n",
      "Epoch: 8/10.  Train Step: 72.  pre_out: 0.5840. Train acc: 0.6689.  Valid acc: 0.4666.  0.3460 sec/batch\n",
      "Epoch: 8/10.  Train Step: 73.  pre_out: 0.5815. Train acc: 0.6768.  Valid acc: 0.4554.  0.3434 sec/batch\n",
      "Epoch: 8/10.  Train Step: 74.  pre_out: 0.5901. Train acc: 0.6982.  Valid acc: 0.4434.  0.3519 sec/batch\n",
      "Epoch: 8/10.  Train Step: 75.  pre_out: 0.5823. Train acc: 0.6641.  Valid acc: 0.4408.  0.3485 sec/batch\n",
      "Epoch: 8/10.  Train Step: 76.  pre_out: 0.5600. Train acc: 0.6895.  Valid acc: 0.4408.  0.3517 sec/batch\n",
      "Epoch: 8/10.  Train Step: 77.  pre_out: 0.5746. Train acc: 0.6904.  Valid acc: 0.4485.  0.3530 sec/batch\n",
      "Epoch: 8/10.  Train Step: 78.  pre_out: 0.5840. Train acc: 0.6934.  Valid acc: 0.4666.  0.3527 sec/batch\n",
      "Epoch: 8/10.  Train Step: 79.  pre_out: 0.6149. Train acc: 0.6807.  Valid acc: 0.4631.  0.3457 sec/batch\n",
      "Epoch: 8/10.  Train Step: 80.  pre_out: 0.6149. Train acc: 0.8222.  Valid acc: 0.4820.  0.1365 sec/batch\n",
      "Epoch: 9/10.  Train Step: 81.  pre_out: 0.6158. Train acc: 0.6924.  Valid acc: 0.4880.  0.3545 sec/batch\n",
      "Epoch: 9/10.  Train Step: 82.  pre_out: 0.5892. Train acc: 0.6748.  Valid acc: 0.4734.  0.3449 sec/batch\n",
      "Epoch: 9/10.  Train Step: 83.  pre_out: 0.5746. Train acc: 0.6855.  Valid acc: 0.4588.  0.3546 sec/batch\n",
      "Epoch: 9/10.  Train Step: 84.  pre_out: 0.5695. Train acc: 0.6992.  Valid acc: 0.4314.  0.3540 sec/batch\n",
      "Epoch: 9/10.  Train Step: 85.  pre_out: 0.5652. Train acc: 0.6709.  Valid acc: 0.4374.  0.3595 sec/batch\n",
      "Epoch: 9/10.  Train Step: 86.  pre_out: 0.5412. Train acc: 0.6973.  Valid acc: 0.4425.  0.3521 sec/batch\n",
      "Epoch: 9/10.  Train Step: 87.  pre_out: 0.5652. Train acc: 0.6934.  Valid acc: 0.4477.  0.3586 sec/batch\n",
      "Epoch: 9/10.  Train Step: 88.  pre_out: 0.5892. Train acc: 0.7061.  Valid acc: 0.4666.  0.3582 sec/batch\n",
      "Epoch: 9/10.  Train Step: 89.  pre_out: 0.6226. Train acc: 0.6807.  Valid acc: 0.4708.  0.3653 sec/batch\n",
      "Epoch: 9/10.  Train Step: 90.  pre_out: 0.6286. Train acc: 0.8311.  Valid acc: 0.4923.  0.1416 sec/batch\n",
      "Epoch: 10/10.  Train Step: 91.  pre_out: 0.6201. Train acc: 0.6895.  Valid acc: 0.4923.  0.3706 sec/batch\n",
      "Epoch: 10/10.  Train Step: 92.  pre_out: 0.5883. Train acc: 0.6777.  Valid acc: 0.4743.  0.3574 sec/batch\n",
      "Epoch: 10/10.  Train Step: 93.  pre_out: 0.5729. Train acc: 0.6885.  Valid acc: 0.4451.  0.3650 sec/batch\n",
      "Epoch: 10/10.  Train Step: 94.  pre_out: 0.5660. Train acc: 0.7012.  Valid acc: 0.4331.  0.3607 sec/batch\n",
      "Epoch: 10/10.  Train Step: 95.  pre_out: 0.5583. Train acc: 0.6846.  Valid acc: 0.4305.  0.3635 sec/batch\n",
      "Epoch: 10/10.  Train Step: 96.  pre_out: 0.5455. Train acc: 0.6934.  Valid acc: 0.4468.  0.3708 sec/batch\n",
      "Epoch: 10/10.  Train Step: 97.  pre_out: 0.5772. Train acc: 0.6914.  Valid acc: 0.4545.  0.3627 sec/batch\n",
      "Epoch: 10/10.  Train Step: 98.  pre_out: 0.5995. Train acc: 0.7109.  Valid acc: 0.4700.  0.3659 sec/batch\n",
      "Epoch: 10/10.  Train Step: 99.  pre_out: 0.6218. Train acc: 0.6914.  Valid acc: 0.4786.  0.3616 sec/batch\n",
      "Epoch: 10/10.  Train Step: 100.  pre_out: 0.6304. Train acc: 0.8533.  Valid acc: 0.4923.  0.1434 sec/batch\n"
     ]
    }
   ],
   "source": [
    "save_every_n = 20000\n",
    "saver = tf.train.Saver()\n",
    "train_data = data['train_dataset']\n",
    "train_w = data['train_w']\n",
    "train_labels = data['train_labels']\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        for x, y, w in get_batches(train_data, train_w, train_labels, batch_size):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {inputs: x,\n",
    "                    targets: y,\n",
    "                    keep_prob: kp,\n",
    "                    weights: w}\n",
    "            batch_loss, accuracy_, pre_out_, _ = sess.run([loss,accuracy,pre_out,opt], feed_dict=feed)\n",
    "            valid_loss, pre_out_,valid_accuracy_= sess.run([loss,pre_out,accuracy], feed_dict={inputs:data['valid_dataset'].reshape(-1,num_features,1),\n",
    "                                                    targets:data['valid_labels'],\n",
    "                                                    keep_prob:1.0,\n",
    "                                                    weights:data['valid_w']})\n",
    "            end = time.time()\n",
    "            print('Epoch: {}/{}. '.format(e+1, epochs),\n",
    "                  'Train Step: {}. '.format(counter),\n",
    "                  'pre_out: {:.4f}.'.format(pre_out_),\n",
    "                  'Train acc: {:.4f}. '.format(accuracy_),\n",
    "                  'Valid acc: {:.4f}. '.format(valid_accuracy_),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"./model/i{}.ckpt\".format(counter))\n",
    "    \n",
    "    saver.save(sess, \"./model/i{}.ckpt\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
